{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\quang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/all-data.csv'\n",
    "headers = ['sentiment', 'content']\n",
    "df = pd.read_csv(\n",
    "    dataset_path,\n",
    "    names=headers,\n",
    "    encoding='ISO-8859-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                            content\n",
       "0      neutral  According to Gran , the company has no plans t...\n",
       "1      neutral  Technopolis plans to develop in stages an area...\n",
       "2     negative  The international electronic industry company ...\n",
       "3     positive  With the new production plant the company woul...\n",
       "4     positive  According to the company 's updated strategy f...\n",
       "...        ...                                                ...\n",
       "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844  negative  Net sales of the Paper segment decreased to EU...\n",
       "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    class_name: idx for idx, class_name in enumerate(df['sentiment'].unique().tolist())\n",
    "}\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'negative': 1, 'positive': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>1</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>1</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>1</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>1</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            content\n",
       "0             0  According to Gran , the company has no plans t...\n",
       "1             0  Technopolis plans to develop in stages an area...\n",
       "2             1  The international electronic industry company ...\n",
       "3             2  With the new production plant the company woul...\n",
       "4             2  According to the company 's updated strategy f...\n",
       "...         ...                                                ...\n",
       "4841          1  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842          0  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843          1  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844          1  Net sales of the Paper segment decreased to EU...\n",
       "4845          1  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def text_normalize(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = unidecode.unidecode(text)  # Remove accents or diacritics\n",
    "    text = text.strip()  # Remove leading and trailing whitespaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in english_stop_words])  # Remove stopwords\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split(' ')])  # Apply stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(text_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>accord gran  compani plan move product russia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>technopoli plan develop stage area less 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>intern electron industri compani elcoteq laid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>new product plant compani would increas capac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>accord compani updat strategi year 20092012  b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>1</td>\n",
       "      <td>london marketwatch  share price end lower lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0</td>\n",
       "      <td>rinkuskiai beer sale fell 65 per cent 416 mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>1</td>\n",
       "      <td>oper profit fell eur 354 mn eur 688 mn 2007  i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>1</td>\n",
       "      <td>net sale paper segment decreas eur 2216 mn sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>1</td>\n",
       "      <td>sale finland decreas 105  januari  sale outsid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            content\n",
       "0             0  accord gran  compani plan move product russia ...\n",
       "1             0  technopoli plan develop stage area less 100000...\n",
       "2             1  intern electron industri compani elcoteq laid ...\n",
       "3             2  new product plant compani would increas capac ...\n",
       "4             2  accord compani updat strategi year 20092012  b...\n",
       "...         ...                                                ...\n",
       "4841          1  london marketwatch  share price end lower lond...\n",
       "4842          0  rinkuskiai beer sale fell 65 per cent 416 mill...\n",
       "4843          1  oper profit fell eur 354 mn eur 688 mn 2007  i...\n",
       "4844          1  net sale paper segment decreas eur 2216 mn sec...\n",
       "4845          1  sale finland decreas 105  januari  sale outsid...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for sentence in df['content'].tolist():\n",
    "    tokens = sentence.split()\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "\n",
    "vocab.append('UNK')  # Unknown token\n",
    "vocab.append('PAD')  # Padding token\n",
    "\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}  # Map words to indices\n",
    "vocab_size = len(vocab)  # Total vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text, word_to_idx, max_seq_len):\n",
    "    tokens = []\n",
    "    for w in text.split():\n",
    "        try:\n",
    "            w_ids = word_to_idx[w]\n",
    "        except:\n",
    "            w_ids = word_to_idx['UNK']\n",
    "        tokens.append(w_ids)\n",
    "\n",
    "    if len(tokens) < max_seq_len:\n",
    "        tokens += [word_to_idx['PAD']] * (max_seq_len - len(tokens))\n",
    "    elif len(tokens) > max_seq_len:\n",
    "        tokens = tokens[:max_seq_len]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "texts = df['content'].tolist()\n",
    "labels = df['sentiment'].tolist()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    texts, labels,\n",
    "    test_size=val_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialNews(Dataset):\n",
    "    def __init__(self, X, y, word_to_idx, max_seq_len, transform=None):\n",
    "        self.texts = X\n",
    "        self.labels = y\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            text = self.transform(\n",
    "                text,\n",
    "                self.word_to_idx,\n",
    "                self.max_seq_len\n",
    "            )\n",
    "\n",
    "        text = torch.tensor(text)\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 32\n",
    "\n",
    "train_dataset = FinancialNews(\n",
    "    X_train, y_train,\n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = FinancialNews(\n",
    "    X_val, y_val,\n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = FinancialNews(\n",
    "    X_test, y_test,\n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_batch_size = 128\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(\n",
    "            self, vocab_size, embedding_dim,\n",
    "            hidden_size, n_layers, n_classes,\n",
    "            dropout_prob\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, n_layers, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc1 = nn.Linear(hidden_size, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hn = self.rnn(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(list(classes.keys()))\n",
    "embedding_dim = 64\n",
    "hidden_size = 64\n",
    "n_layers = 2\n",
    "dropout_prob = 0.2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentimentClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    n_classes=n_classes,\n",
    "    dropout_prob=dropout_prob\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs\n",
    "):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_train_losses = []\n",
    "        model.train()\n",
    "        for idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_train_losses.append(loss.item())\n",
    "        \n",
    "        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss, val_acc = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    loss = sum(losses) / len(losses)\n",
    "    acc = correct / total\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\tTrain loss: 0.9977\tVal loss: 0.9653\n",
      "EPOCH 2:\tTrain loss: 0.9609\tVal loss: 0.9475\n",
      "EPOCH 3:\tTrain loss: 0.9439\tVal loss: 0.9370\n",
      "EPOCH 4:\tTrain loss: 0.9374\tVal loss: 0.9330\n",
      "EPOCH 5:\tTrain loss: 0.9349\tVal loss: 0.9309\n",
      "EPOCH 6:\tTrain loss: 0.9310\tVal loss: 0.9298\n",
      "EPOCH 7:\tTrain loss: 0.9297\tVal loss: 0.9299\n",
      "EPOCH 8:\tTrain loss: 0.9296\tVal loss: 0.9293\n",
      "EPOCH 9:\tTrain loss: 0.9273\tVal loss: 0.9289\n",
      "EPOCH 10:\tTrain loss: 0.9285\tVal loss: 0.9288\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on val/test dataset\n",
      "Val accuracy:  0.5865979381443299\n",
      "Test accuracy:  0.6144329896907217\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = evaluate(\n",
    "    model,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "test_loss, test_acc = evaluate(\n",
    "    model,\n",
    "    test_loader,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "\n",
    "print('Evaluation on val/test dataset')\n",
    "print('Val accuracy: ', val_acc)\n",
    "print('Test accuracy: ', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
